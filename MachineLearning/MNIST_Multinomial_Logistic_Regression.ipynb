{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#TRAINING IMAGES INPUT\n",
    "import gzip\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "f = gzip.open('train-images-idx3-ubyte.gz','r') #f is a file\n",
    "image_size = 28  #originally 28\n",
    "num_images = 60000\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(image_size * image_size * num_images)\n",
    "data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "data = data.reshape(num_images, image_size, image_size, 1)\n",
    "print(data.shape)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "#TRAINING LABELS INPUT\n",
    "f = gzip.open('train-labels-idx1-ubyte.gz','r') #f is a file\n",
    "f.read(8)\n",
    "z = f.read() #z is a bytes #z has all the labels\n",
    "labels = []\n",
    "for i in z:\n",
    "    labels.append(i)\n",
    "labels = np.array(labels)\n",
    "#len(bites)\n",
    "print(labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#TEST IMAGES \n",
    "f = gzip.open('t10k-images-idx3-ubyte.gz','r') #f is a file\n",
    "image_size = 28  #originally 28\n",
    "num_images = 10000\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(image_size * image_size * num_images)\n",
    "data1 = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "data1 = data1.reshape(num_images, image_size, image_size, 1)\n",
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST LABELS\n",
    "f = gzip.open('t10k-labels-idx1-ubyte.gz','r') #f is a file\n",
    "f.read(8)\n",
    "z = f.read() #z is a bytes #z has all the labels\n",
    "labels2 = []\n",
    "for i in z:\n",
    "    labels2.append(i)\n",
    "labels2 = np.array(labels2)\n",
    "len(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n"
     ]
    }
   ],
   "source": [
    "#want to combine test and train data\n",
    "#let's first combine the labels #bites\n",
    "labels = labels.tolist()\n",
    "len(labels)\n",
    "labels2 = labels2.tolist()\n",
    "len(labels2)\n",
    "labels = labels + labels2\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sup\n",
      "hi\n",
      "hello\n",
      "(70000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#combining data arrays\n",
    "data = data.tolist()\n",
    "print(\"sup\")\n",
    "data1 = data1.tolist()\n",
    "print(\"hi\")\n",
    "data = data + data1\n",
    "print(\"hello\")\n",
    "data = np.array(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors 70000\n"
     ]
    }
   ],
   "source": [
    "#manipulating data array so that each row is a picture and columns are the bits\n",
    "#print(data[0,:,:].shape)\n",
    "#print(data[3,4:24,:,0]) #data[i,:,:,0] return ith matrix with blank header and footer\n",
    "#data[i,4:-4,:,0] return ith matrix without footers\n",
    "\n",
    "vectors = []\n",
    "for matrix in range(70000):#70000\n",
    "    vector = []\n",
    "    for row in range(4,24):\n",
    "        for col in range(0,28):\n",
    "            vector.append(data[matrix,row,col,0])\n",
    "    #print(vector)\n",
    "    \n",
    "    vectors.append(vector)\n",
    "print(\"vectors \",end=\"\")\n",
    "print(len(vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(70000, 560)\n"
     ]
    }
   ],
   "source": [
    "vectors = np.array(vectors)\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAVwAAAD4CAYAAACg7F5gAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAS2ElEQVR4nO3df7BXdZ3H8dery69EVMggBfxRMU5urVh3MNet1UhCxoksK5idorSuNTlTk/1w3SabmmbaNXN3o41uij92jdytNHZyVYZyqNlCLoQCiUEs6fUSZJRgFnAv7/3jHnZut++X++H7/d7P93u+PB8zd77ne877e877cODF4XA+3+OIEABg9L2g2Q0AwPGCwAWATAhcAMiEwAWATAhcAMhkTLMbqGScx8cETWx2GwBwzP6o3+tgHHClZS0ZuBM0URd4brPbAIBjtjZWV13GJQUAyKSuwLU93/YTtrfbvr7C8vG27ymWr7V9Vj3bA4AyqzlwbXdI+oqkyySdK2mx7XOHlV0t6bcR8XJJt0j6h1q3BwBlV88Z7hxJ2yNiR0QclPRNSQuH1SyUdGcx/S1Jc21XvJgMAO2unsCdLumpIe97i3kVayKiX9Kzkl5UaWW2u2z32O45pAN1tAUAramewK10pjr8m3BSagZnRnRHRGdEdI7V+DraAoDWVE/g9kqaOeT9DEl91Wpsj5F0sqS9dWwTAEqrnsBdJ2mW7bNtj5O0SNLKYTUrJS0ppq+U9P3g+yABHKdqHvgQEf22r5X0oKQOScsjYovtz0rqiYiVkm6T9G+2t2vwzHZRI5oGgDJyK55wnuQpwUgzAGW0NlZrX+yteDcWI80AIBMCFwAyIXABIBMCFwAyIXABIBMCFwAyIXABIBMCFwAyIXABIBMCFwAyIXABIBMCFwAyIXABIBMCFwAyIXABIBMCFwAyIXABIBMCFwAyqTlwbc+0/QPbj9veYvvDFWoutv2s7Y3Fz6fraxcAyqvmh0hK6pd0XURssD1J0nrbqyLiZ8PqfhgRl9exHQBoCzWf4UbErojYUEzvl/S4pOmNagwA2k09Z7j/z/ZZks6XtLbC4gttPyqpT9LHImJLlXV0SeqSpAk6oRFtoU4H39SZXPuD228dlR6W/S797/DuL785qe7FX3skvYHDA+m1wAjqDlzbJ0r6tqSPRMS+YYs3SDozIp6zvUDSfZJmVVpPRHRL6pYGH5Neb18A0GrqukvB9lgNhu3dEfGd4csjYl9EPFdM3y9prO1T69kmAJRVPXcpWNJtkh6PiC9VqXlJUSfbc4rt/abWbQJAmdVzSeEiSe+StMn2xmLeDZLOkKSIWCbpSkkftN0v6Q+SFkUElwsAHJdqDtyI+JEkj1CzVNLSWrcBAO2EkWYAkAmBCwCZELgAkAmBCwCZELgAkElDhvaiPDqmTU2uHfeJXyXXDsThWtoZ0ftPfiq99lNfSaqbv+mq5HWO6/tdci0G7X7Dacm1076/K6lu4Mne5HVGf39ybW6c4QJAJgQuAGRC4AJAJgQuAGRC4AJAJgQuAGRC4AJAJgQuAGRC4AJAJm7F7wM/yVPiAs9tdhul4bHjkmv3/9eM5No1r/pWLe001JZDB5Nr/+IYfh1GQ4fTz19Ga2Reu1pwxZL04kc2jV4jCdbGau2LvRW/K5wzXADIhMAFgEzqDlzbO21vsr3Rdk+F5bb9L7a3237M9qvr3SYAlFGjvi3skoh4psqyyyTNKn4ukPTV4hUAjis5LikslHRXDPqJpFNsp39/GwC0iUYEbkh6yPZ6210Vlk+XNPRLTXuLeX/CdpftHts9h3SgAW0BQGtpxCWFiyKiz/ZUSatsb42INUOWV7o94s/uRYuIbknd0uBtYQ3oCwBaSt1nuBHRV7zukXSvpDnDSnolzRzyfoakvnq3CwBlU1fg2p5oe9KRaUnzJG0eVrZS0ruLuxVeK+nZiEh7rgYAtJF6LylMk3Sv7SPr+kZEPGD7A5IUEcsk3S9pgaTtkp6X9N46twkApVRX4EbEDknnVZi/bMh0SPpQPdvB0T318c7k2sdetXRUenh64Pnk2nm3fyK59owHf59ce+pNTybVdZ/538nrfKGbO1wYg3a87cTk2pc+MoqN1ImRZgCQCYELAJkQuACQCYELAJkQuACQCYELAJkQuACQCYELAJkQuACQCYELAJk06okPaLAXTJqUXPv59941Kj0cy3DdhV9IH6575r/+Ty3tjOg3F6XVzX/bh5PXOTCu4sNXs/r96ennRT/96OgM3T4W6w8OJNdec1PasXj5HRuT19nKz0PmDBcAMiFwASATAhcAMiFwASATAhcAMiFwASATAhcAMqk5cG2fY3vjkJ99tj8yrOZi288Oqfl0/S0DQDnVPPAhIp6QNFuSbHdIelqDj0kf7ocRcXmt2wGAdtGoSwpzJf0iIn7ZoPUBQNtp1NDeRZJWVFl2oe1HJfVJ+lhEbKlUZLtLUpckTdAJDWrr+DAQ6X9vPvCH9F/bW973vuTaqQ+PznDd0TDx22ub3YIOzUt/0vIln2j+Y2iv+9Wc5NqtH3hFcu3UdWm/b1p5uO6xqPsM1/Y4SW+W9J8VFm+QdGZEnCfpy5Luq7aeiOiOiM6I6Byr8fW2BQAtpxGXFC6TtCEidg9fEBH7IuK5Yvp+SWNtn9qAbQJA6TQicBeryuUE2y+x7WJ6TrG93zRgmwBQOnVdw7V9gqRLJV0zZN4HJCkilkm6UtIHbfdL+oOkRRER9WwTAMqqrsCNiOclvWjYvGVDppdKav4XdAJAC2CkGQBkQuACQCYELgBkQuACQCYELgBkwlN7W9Th/fuTa2+7/NLk2oFT0of2djyyIbkWksenj5A84Yank2s/NzX9ibVbDx1Irn3vlncn1074+uTk2heua/5Q5FbFGS4AZELgAkAmBC4AZELgAkAmBC4AZELgAkAmBC4AZELgAkAmBC4AZELgAkAmDO1tAwM//0WzW2hbh193fnLtnuv+mFy7YdbdtbQzorf3vD+5duaVm0elB1THGS4AZJIUuLaX295je/OQeVNsr7K9rXit+O0WtpcUNdtsL2lU4wBQNqlnuHdImj9s3vWSVkfELEmri/d/wvYUSTdKukDSHEk3VgtmAGh3SYEbEWsk7R02e6GkO4vpOyW9pcJH3yRpVUTsjYjfSlqlPw9uADgu1HMNd1pE7JKk4nVqhZrpkp4a8r63mAcAx53RvkvBFeZFxUK7S1KXJE1Q+pdkA0BZ1HOGu9v2aZJUvO6pUNMraeaQ9zMk9VVaWUR0R0RnRHSOVfo35wNAWdQTuCslHbnrYImk71aoeVDSPNuTi/8sm1fMA4DjTuptYSsk/VjSObZ7bV8t6QuSLrW9TdKlxXvZ7rR9qyRFxF5Jn5O0rvj5bDEPAI47SddwI2JxlUVzK9T2SHrfkPfLJS2vqTsAaCMM7QWOYuflE5Jrt825Pbl2oOJ/HVd24cZ3JteeueR/k2sPp7eABmFoLwBkQuACQCYELgBkQuACQCYELgBkQuACQCYELgBkQuACQCYELgBkQuACQCYM7cVx59AbX5Ncu3rxTcew5hOTK/9m05XJtVPe+mRy7eEDB5JrkR9nuACQCYELAJkQuACQCYELAJkQuACQCYELAJkQuACQyYiBa3u57T22Nw+Zd5PtrbYfs32v7VOqfHan7U22N9ruaWTjAFA2KWe4d0iaP2zeKkmvjIi/lPRzSX93lM9fEhGzI6KzthYBoD2MGLgRsUbS3mHzHoqI/uLtTyTNGIXeAKCtNGJo71WS7qmyLCQ9ZDskfS0iuqutxHaXpC5JmqATGtAWUFn/x/eOXFQ4Y0z6cN3nDv8xuXb8TZOTa+PAjuRatLa6Atf230vql3R3lZKLIqLP9lRJq2xvLc6Y/0wRxt2SdJKnHMNDpAGgHGq+S8H2EkmXS/rbiKgYkBHRV7zukXSvpDm1bg8Ayq6mwLU9X9InJb05Ip6vUjPR9qQj05LmSdpcqRYAjgcpt4WtkPRjSefY7rV9taSlkiZp8DLBRtvLitrTbd9ffHSapB/ZflTSI5K+FxEPjMpeAEAJjHgNNyIWV5h9W5XaPkkLiukdks6rqzsAaCOMNAOATAhcAMiEwAWATAhcAMiEwAWATHhqL9rGL25+bVLdw6/4YvI6ByJ9mPmF665Krj199frkWrQPznABIBMCFwAyIXABIBMCFwAyIXABIBMCFwAyIXABIBMCFwAyIXABIBNGmiG7jlNOTq59ZuG5ybUPXnlTUt1pHemjx7YcOphce/oVP0uuxfGJM1wAyITABYBMUp5pttz2Htubh8z7jO2ni+eZbbS9oMpn59t+wvZ229c3snEAKJuUM9w7JM2vMP+WiJhd/Nw/fKHtDklfkXSZpHMlLbadfkEOANrMiIEbEWsk7a1h3XMkbY+IHRFxUNI3JS2sYT0A0BbquYZ7re3HiksOkyssny7pqSHve4t5Fdnust1ju+eQDtTRFgC0ploD96uSXiZptqRdkm6uUOMK86LaCiOiOyI6I6JzrMbX2BYAtK6aAjcidkfEQEQclvR1DV4+GK5X0swh72dI6qtlewDQDmoKXNunDXl7haTNFcrWSZpl+2zb4yQtkrSylu0BQDsYcaSZ7RWSLpZ0qu1eSTdKutj2bA1eItgp6Zqi9nRJt0bEgojot32tpAcldUhaHhFbRmUvAKAEHFH1smrTnOQpcYHnNrsNjJJdH/2r5NqfXre04dtfdyD99/ynrnp/cm3HwxtqaQdtZm2s1r7YW+n/sBhpBgC5ELgAkAmBCwCZELgAkAmBCwCZELgAkAmBCwCZELgAkAmBCwCZELgAkAlP7UVVHZMrfc1xZVv/+ezk2vte/6Vj6GJccuUNe16dVNfzsdckr3PMw+uTa4GRcIYLAJkQuACQCYELAJkQuACQCYELAJkQuACQCYELAJmkPNNsuaTLJe2JiFcW8+6RdE5Rcoqk30XE7Aqf3Slpv6QBSf0R0dmgvgGgdFIGPtwhaamku47MiIh3Hpm2fbOkZ4/y+Usi4plaGwSAdjFi4EbEGttnVVpm25LeIekNjW0LANpPvUN7Xydpd0Rsq7I8JD1kOyR9LSK6q63IdpekLkmaoBPqbAvVdJxycnLtzg+9Irl229xjebpu+nDdd+1Mf3rzb+f3J9WN2c9wXTRHvYG7WNKKoyy/KCL6bE+VtMr21ohYU6mwCONuafAx6XX2BQAtp+a7FGyPkfRWSfdUq4mIvuJ1j6R7Jc2pdXsAUHb13Bb2RklbI6K30kLbE21POjItaZ6kzXVsDwBKbcTAtb1C0o8lnWO71/bVxaJFGnY5wfbptu8v3k6T9CPbj0p6RNL3IuKBxrUOAOWScpfC4irz31NhXp+kBcX0Dknn1dkfALQNRpoBQCYELgBkQuACQCYELgBkQuACQCY8tbcNvGDSpOTaX//7tOTaTecfy3DddMcyXHfXZ1+WXDtuf08t7QDZcIYLAJkQuACQCYELAJkQuACQCYELAJkQuACQCYELAJkQuACQCYELAJkQuACQiSNa73mNtn8t6ZfDZp8q6ZkmtDPa2nW/pPbdN/arfHLu25kR8eJKC1oycCux3RMRnc3uo9Hadb+k9t039qt8WmXfuKQAAJkQuACQSZkCt7vZDYySdt0vqX33jf0qn5bYt9JcwwWAsivTGS4AlBqBCwCZlCJwbc+3/YTt7bavb3Y/jWJ7p+1NtjfaLvXzYWwvt73H9uYh86bYXmV7W/E6uZk91qLKfn3G9tPFcdtoe0Eze6yF7Zm2f2D7cdtbbH+4mF/qY3aU/WqJY9by13Btd0j6uaRLJfVKWidpcUT8rKmNNYDtnZI6I6L0N5vbfr2k5yTdFRGvLOb9o6S9EfGF4i/KyRHxyWb2eayq7NdnJD0XEV9sZm/1sH2apNMiYoPtSZLWS3qLpPeoxMfsKPv1DrXAMSvDGe4cSdsjYkdEHJT0TUkLm9wThomINZL2Dpu9UNKdxfSdGvyNXypV9qv0ImJXRGwopvdLelzSdJX8mB1lv1pCGQJ3uqSnhrzvVQv9AtYpJD1ke73trmY3MwqmRcQuafAPgqSpTe6nka61/VhxyaFU/+wezvZZks6XtFZtdMyG7ZfUAsesDIHrCvNa+zpIuosi4tWSLpP0oeKfr2h9X5X0MkmzJe2SdHNz26md7RMlfVvSRyJiX7P7aZQK+9USx6wMgdsraeaQ9zMk9TWpl4aKiL7idY+kezV4+aSd7C6uqR25tranyf00RETsjoiBiDgs6esq6XGzPVaDoXR3RHynmF36Y1Zpv1rlmJUhcNdJmmX7bNvjJC2StLLJPdXN9sTior5sT5Q0T9Lmo3+qdFZKWlJML5H03Sb20jBHAqlwhUp43Gxb0m2SHo+ILw1ZVOpjVm2/WuWYtfxdCpJU3MLxT5I6JC2PiM83uaW62X6pBs9qJWmMpG+Ueb9sr5B0sQa/Bm+3pBsl3SfpPySdIelJSW+PiFL9B1SV/bpYg/80DUk7JV1z5LpnWdj+a0k/lLRJ0uFi9g0avN5Z2mN2lP1arBY4ZqUIXABoB2W4pAAAbYHABYBMCFwAyITABYBMCFwAyITABYBMCFwAyOT/AJXdRna+w6BmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import time\n",
    "for i in range(69000,69001):\n",
    "    #print(data[1])\n",
    "    image = np.asarray(data[i,4:24,:,0]).squeeze()\n",
    "    plt.imshow(image)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n"
     ]
    }
   ],
   "source": [
    "#need to one hot encode the output layer\n",
    "X = data\n",
    "y = labels\n",
    "print(len(labels))\n",
    "#y = pd.DataFrame(y,columns=[\"Labels\"])\n",
    "#y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = pd.get_dummies(y,columns=[\"Labels\"])\n",
    "#y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y = y.to_numpy()\n",
    "#print(y.shape)\n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 560)\n",
      "(14000, 560)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the dataset into the Training set and Test set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, y, test_size = 0.2, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Logistic Regression model on the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0,multi_class=\"multinomial\", solver='newton-cg')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7]\n"
     ]
    }
   ],
   "source": [
    "#Predicting a new result\n",
    "print(classifier.predict(sc.transform([vectors[69000]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[8 5 7 9 0 3 2 7 4 6]\n",
      "[8, 5, 9, 4, 0, 3, 2, 7, 4, 6]\n"
     ]
    }
   ],
   "source": [
    "y_pred = classifier.predict(X_test)\n",
    "print(type(y_pred))\n",
    "print(y_pred[-10:])\n",
    "print(y_test[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1331    0    8    2    3   17   15    5    6    0]\n",
      " [   0 1537    9    2    2    7    3    4   14    2]\n",
      " [  11   16 1282   18   23   10   20   19   40    4]\n",
      " [   6    8   48 1246    0   49    3   20   35   20]\n",
      " [   3    3   12    1 1242    4   15   15    5   50]\n",
      " [  11    5   14   37   15 1065   24    8   40   12]\n",
      " [  20    6   15    1   22   18 1293    3    9    0]\n",
      " [   6    8   19    5   16    5    1 1332    8   58]\n",
      " [   7   33   13   36   12   40   15    3 1193   16]\n",
      " [   4    9    5   16   56   13    1   45   12 1200]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9086428571428572"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
