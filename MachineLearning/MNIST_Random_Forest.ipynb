{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "#TRAINING IMAGES INPUT\n",
    "import gzip\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "\n",
    "f = gzip.open('train-images-idx3-ubyte.gz','r') #f is a file\n",
    "image_size = 28  #originally 28\n",
    "num_images = 60000\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(image_size * image_size * num_images)\n",
    "data = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "data = data.reshape(num_images, image_size, image_size, 1)\n",
    "print(data.shape)\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n"
     ]
    }
   ],
   "source": [
    "#TRAINING LABELS INPUT\n",
    "f = gzip.open('train-labels-idx1-ubyte.gz','r') #f is a file\n",
    "f.read(8)\n",
    "z = f.read() #z is a bytes #z has all the labels\n",
    "labels = []\n",
    "for i in z:\n",
    "    labels.append(i)\n",
    "labels = np.array(labels)\n",
    "#len(bites)\n",
    "print(labels.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#TEST IMAGES \n",
    "f = gzip.open('t10k-images-idx3-ubyte.gz','r') #f is a file\n",
    "image_size = 28  #originally 28\n",
    "num_images = 10000\n",
    "\n",
    "f.read(16)\n",
    "buf = f.read(image_size * image_size * num_images)\n",
    "data1 = np.frombuffer(buf, dtype=np.uint8).astype(np.float32)\n",
    "data1 = data1.reshape(num_images, image_size, image_size, 1)\n",
    "print(data1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#TEST LABELS\n",
    "f = gzip.open('t10k-labels-idx1-ubyte.gz','r') #f is a file\n",
    "f.read(8)\n",
    "z = f.read() #z is a bytes #z has all the labels\n",
    "labels2 = []\n",
    "for i in z:\n",
    "    labels2.append(i)\n",
    "labels2 = np.array(labels2)\n",
    "len(labels2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70000\n"
     ]
    }
   ],
   "source": [
    "#want to combine test and train data\n",
    "#let's first combine the labels #bites\n",
    "labels = labels.tolist()\n",
    "len(labels)\n",
    "labels2 = labels2.tolist()\n",
    "len(labels2)\n",
    "labels = labels + labels2\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sup\n",
      "hi\n",
      "hello\n",
      "(70000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "#combining data arrays\n",
    "data = data.tolist()\n",
    "print(\"sup\")\n",
    "data1 = data1.tolist()\n",
    "print(\"hi\")\n",
    "data = data + data1\n",
    "print(\"hello\")\n",
    "data = np.array(data)\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vectors 70000\n",
      "(70000, 560)\n"
     ]
    }
   ],
   "source": [
    "#manipulating data array so that each row is a picture and columns are the bits\n",
    "#print(data[0,:,:].shape)\n",
    "#print(data[3,4:24,:,0]) #data[i,:,:,0] return ith matrix with blank header and footer\n",
    "#data[i,4:-4,:,0] return ith matrix without footers\n",
    "\n",
    "vectors = []\n",
    "for matrix in range(70000):#70000\n",
    "    vector = []\n",
    "    for row in range(4,24):\n",
    "        for col in range(0,28):\n",
    "            vector.append(data[matrix,row,col,0])\n",
    "    #print(vector)\n",
    "    \n",
    "    vectors.append(vector)\n",
    "print(\"vectors \",end=\"\")\n",
    "print(len(vectors))\n",
    "vectors = np.array(vectors)\n",
    "print(vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56000, 560)\n",
      "(14000, 560)\n"
     ]
    }
   ],
   "source": [
    "#Splitting the dataset into the Training set and Test set\n",
    "X = data\n",
    "y = labels\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(vectors, y, test_size = 0.2, random_state = 0)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
       "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                       warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the Random Forest model on the Training set\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = RandomForestClassifier(n_estimators=100,criterion=\"entropy\",random_state=0)\n",
    "classifier.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the test set results using our model\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1365    0    3    0    2    2    6    0    9    0]\n",
      " [   0 1561    3    3    3    1    1    4    2    2]\n",
      " [   3    3 1399    6    5    2    7    9    7    2]\n",
      " [   1    2   24 1357    0   18    0   14   17    2]\n",
      " [   3    0    1    0 1306    0    3    4    4   29]\n",
      " [   1    6    3   13    2 1173   15    0   11    7]\n",
      " [   5    2    1    0    3    7 1365    0    4    0]\n",
      " [   2    6   23    2   11    0    0 1394    2   18]\n",
      " [   1    7    5    5    5    7    3    0 1314   21]\n",
      " [   5    3    4   21   18    7    2   16    8 1277]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9650714285714286"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#making confusion matrix\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
